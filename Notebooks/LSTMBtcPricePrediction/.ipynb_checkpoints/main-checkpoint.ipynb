{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60                 #window size : 60 minutes \n",
    "FUTURE_PERIOD_PREDICT = 3    #predict : 3 minutes\n",
    "RATIO_TO_PREDICT = \"BTC-USD\" #predict : BTC-USD price\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> DÃ©finition des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1 #1 veut dire qu'on doit acheter\n",
    "    else:\n",
    "        return 0 #0 veut dire qu'on doit vendre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \n",
      "time                                                                      \n",
      "1528968720     870.859985       26.856577      486.01001       26.019083  \n",
      "1528968780     870.099976        1.124300      486.00000        8.449400  \n",
      "1528968840     870.789978        1.749862      485.75000       26.994646  \n"
     ]
    }
   ],
   "source": [
    "main_df = pd.DataFrame()\n",
    "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]\n",
    "for ratio in ratios:\n",
    "    ratio = ratio.split('.csv')[0] #On enleve le .csv\n",
    "    dataset = f\"crypto_data/{ratio}.csv\"\n",
    "    df = pd.read_csv(dataset, names=[\"time\", \"low\", \"high\", \"open\", \"close\", \"volume\"])\n",
    "    #print(ratio)\n",
    "    #print(df.head(3))\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\",\n",
    "                       \"volume\": f\"{ratio}_volume\"},\n",
    "                       inplace=True\n",
    "                        )\n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]\n",
    "    #print('=====================================================================================')\n",
    "    #print(df.head(5))\n",
    "    if len(main_df) == 0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df)        \n",
    "        \n",
    "main_df.fillna(method=\"ffill\", inplace=True) #Si il y a des \"trous\" dans les donnees, on utilise les anciennes donnees\n",
    "main_df.dropna(inplace=True)\n",
    "        \n",
    "print(main_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close       future\n",
      "time                                  \n",
      "1528968720    6487.379883  6479.979980\n",
      "1528968780    6479.410156  6480.000000\n",
      "1528968840    6479.410156  6477.220215\n"
     ]
    }
   ],
   "source": [
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\", \"future\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close       future  target\n",
      "time                                          \n",
      "1528968720    6487.379883  6479.979980       0\n",
      "1528968780    6479.410156  6480.000000       1\n",
      "1528968840    6479.410156  6477.220215       0\n",
      "1528968900    6479.979980  6480.000000       1\n",
      "1528968960    6480.000000  6479.990234       0\n",
      "1528969020    6477.220215  6478.660156       1\n",
      "1528969080    6480.000000  6478.660156       0\n",
      "1528969140    6479.990234  6479.339844       0\n",
      "1528969200    6478.660156  6479.350098       1\n",
      "1528969260    6478.660156  6479.990234       1\n"
     ]
    }
   ],
   "source": [
    "main_df['target'] = list(map(classify, \n",
    "                             main_df[f'{RATIO_TO_PREDICT}_close'], \n",
    "                             main_df['future']))\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\", \"future\", \"target\"]].head(10))\n",
    "#Ici un \"1\" en target signifie que 3 lignes plus tard le prix a augmente\n",
    "main_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534921920\n"
     ]
    }
   ],
   "source": [
    "times = sorted(main_df.index.values)\n",
    "last_5_percent = sorted(main_df.index.values)[-int(0.05*len(times))]\n",
    "print(last_5_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1534921920    6686.250000        2.678847      57.509998        6.070000   \n",
      "1534921980    6686.250000        0.220156      57.509998       15.697691   \n",
      "1534922040    6685.000000        6.401611      57.509998        0.212400   \n",
      "1534922100    6684.500000        0.969366      57.509998       66.463028   \n",
      "1534922160    6684.500000        0.611018      57.509998        3.616516   \n",
      "...                   ...             ...            ...             ...   \n",
      "1535214780    6708.379883        0.975295      58.009998       14.458084   \n",
      "1535214840    6710.089844        1.293573      58.009998       93.464951   \n",
      "1535214900    6712.990234        2.330975      58.020000        0.823356   \n",
      "1535214960    6713.140137        0.769891      58.020000        6.434783   \n",
      "1535215020    6714.520020        1.002652      58.009998        7.301921   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \\\n",
      "time                                                                       \n",
      "1534921920     551.299988        5.713912     285.739990        6.953944   \n",
      "1534921980     551.299988        5.713912     286.000000       24.460905   \n",
      "1534922040     551.289978        0.264895     285.850006        6.233958   \n",
      "1534922100     550.719971        5.058020     285.739990      194.228867   \n",
      "1534922160     550.710022        0.136300     285.730011       11.172032   \n",
      "...                   ...             ...            ...             ...   \n",
      "1535214780     531.479980        0.100199     279.299988        6.183691   \n",
      "1535214840     531.479980        0.044015     279.290009        4.150405   \n",
      "1535214900     531.469971        1.761348     279.299988        5.566861   \n",
      "1535214960     531.479980        1.208560     279.359985       11.280577   \n",
      "1535215020     531.479980        0.016868     279.359985        8.790519   \n",
      "\n",
      "                 future  target  \n",
      "time                             \n",
      "1534921920  6684.500000       0  \n",
      "1534921980  6684.500000       0  \n",
      "1534922040  6682.740234       0  \n",
      "1534922100  6682.660156       0  \n",
      "1534922160  6682.450195       0  \n",
      "...                 ...     ...  \n",
      "1535214780  6713.140137       1  \n",
      "1535214840  6714.520020       1  \n",
      "1535214900  6714.520020       1  \n",
      "1535214960  6715.000000       1  \n",
      "1535215020  6715.000000       1  \n",
      "\n",
      "[4886 rows x 10 columns]\n",
      "========================================================================================\n",
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "1528968960    6480.000000        1.490900      96.519997       16.991997   \n",
      "...                   ...             ...            ...             ...   \n",
      "1534921620    6686.240234        0.444371      57.500000        1.400042   \n",
      "1534921680    6686.250000        0.254431      57.500000        0.926196   \n",
      "1534921740    6686.250000        0.303292      57.500000        2.674066   \n",
      "1534921800    6686.250000        0.478039      57.509998       18.782650   \n",
      "1534921860    6686.250000        0.440793      57.500000        8.449425   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720     870.859985       26.856577     486.010010       26.019083   \n",
      "1528968780     870.099976        1.124300     486.000000        8.449400   \n",
      "1528968840     870.789978        1.749862     485.750000       26.994646   \n",
      "1528968900     870.000000        1.680500     486.000000       77.355759   \n",
      "1528968960     869.989990        1.669014     486.000000        7.503300   \n",
      "...                   ...             ...            ...             ...   \n",
      "1534921620     551.299988        0.561800     285.140015        1.022109   \n",
      "1534921680     551.289978        0.350000     285.130005       12.163237   \n",
      "1534921740     551.289978        0.350000     285.140015       10.175691   \n",
      "1534921800     551.299988        0.336000     285.230011       38.141129   \n",
      "1534921860     551.299988        0.010847     285.489990       17.549879   \n",
      "\n",
      "                 future  target  \n",
      "time                             \n",
      "1528968720  6479.979980       0  \n",
      "1528968780  6480.000000       1  \n",
      "1528968840  6477.220215       0  \n",
      "1528968900  6480.000000       1  \n",
      "1528968960  6479.990234       0  \n",
      "...                 ...     ...  \n",
      "1534921620  6686.250000       1  \n",
      "1534921680  6686.250000       0  \n",
      "1534921740  6686.250000       0  \n",
      "1534921800  6686.250000       0  \n",
      "1534921860  6685.000000       0  \n",
      "\n",
      "[92834 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "validation_main_df = main_df[(main_df.index >= last_5_percent)]\n",
    "main_df = main_df[(main_df.index < last_5_percent)]\n",
    "print(validation_main_df)\n",
    "print(\"========================================================================================\")\n",
    "print(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", 1)                             #Il faut enlever le future sinon le NN va s'en servir\n",
    "    for col in df.columns:                                \n",
    "        if col != \"target\":                               #On normalize et scale tous sauf les targets qui restent 0 ou 1\n",
    "            df[col] = df[col].pct_change()                #Normalize la data\n",
    "            df.dropna(inplace=True)                       #Supprime les bugs\n",
    "            df[col] = preprocessing.scale(df[col].values) #Preprocessing scale les valeurs\n",
    "    df.dropna(inplace=True)                               \n",
    "    \n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=SEQ_LEN)                     #Continuer d'ajouter de la data jusqu'au \"maxlen\" puis pop out les vieux items\n",
    "#     print(df.head(10))\n",
    "#     print(\"===================================================================\")\n",
    "#     for c in df.columns:\n",
    "#         print(c)\n",
    "    for i in df.values:                                   #On prends les values donc il n'y a plus le temps mais il y a toujours les targets\n",
    "        prev_days.append([n for n in i[:-1]])             #\"n for n\" sont les colonnes, sans le dernier i qui correspond aux targets\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "    random.shuffle(sequential_data)                       #Melange les donnees \n",
    "    \n",
    "    buys = []\n",
    "    sells = []\n",
    "    for seq, target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq, target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq, target])\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    lower = min(len(buys), len(sells))\n",
    "    buys = buys[:lower]                                   #Balance les donnes\n",
    "    sells = sells[:lower]\n",
    "    sequential_data = buys + sells\n",
    "    random.shuffle(sequential_data)                       #Le model doit avoir des buys et sells aleatoires pour l'entrainement\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "        \n",
    "    print(y[:5])\n",
    "    print(\"=======================================================\")\n",
    "    return np.array(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92834, 10)\n",
      "(4886, 10)\n",
      "[0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "=======================================================\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "=======================================================\n",
      "(60, 8) 83156\n",
      "(60, 8) 4478\n"
     ]
    }
   ],
   "source": [
    "print(main_df.shape)\n",
    "print(validation_main_df.shape)\n",
    "train_x, train_y = preprocess_df(main_df)\n",
    "valid_x, valid_y = preprocess_df(validation_main_df)\n",
    "print(train_x[0].shape, len(train_y))\n",
    "print(valid_x[0].shape, len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 83156 validation : 4478\n",
      "dont buy: 41578 buy : 41578\n",
      "validation dont buy: 2239 validation buy : 2239\n"
     ]
    }
   ],
   "source": [
    "print(f\"train data: {len(train_x)} validation : {len(valid_x)}\")\n",
    "print(f\"dont buy: {train_y.count(0)} buy : {train_y.count(1)}\")\n",
    "print(f\"validation dont buy: {valid_y.count(0)} validation buy : {valid_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Building model\n",
    "\n",
    ">Ce model est un RNN, LSTM qui fait de la prediction de prix de plusieurs cryptomonnaies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60, 128)           70144     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 60, 128)           512       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 60, 128)           512       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 339,042\n",
      "Trainable params: 338,274\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1300/1300 [==============================] - 170s 127ms/step - loss: 0.7823 - accuracy: 0.5132 - val_loss: 0.6903 - val_accuracy: 0.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\RNN_Final-01-0.522.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\RNN_Final-01-0.522.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " 785/1300 [=================>............] - ETA: 1:07 - loss: 0.6888 - accuracy: 0.5384"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-486bcd7b9ff0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m history = model.fit(np.asarray(train_x),  np.asarray(train_y), \n\u001b[0m\u001b[0;32m     40\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#On ne specifie pas la fonction d'activation. Cela appelle le LSTM de CuDNN, qui utilise sa propre fonction d'activation.\n",
    "#CuDNNLSTM utilise la fonction d'activation tanh\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-6)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer = optimizer,\n",
    "    metrics = [\"accuracy\"]\n",
    "    )\n",
    "\n",
    "#On recupere les infos avec \"tensorboard --logdir=logs/\"\n",
    "#Et on visualise ici : http://localhost:6006/\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{NAME}\") \n",
    "\n",
    "file_path = \"RNN_Final-{epoch:02d}-{val_accuracy:.3f}\"  #Nom de fichier unique avec le nombre d'epochs et l'accuracy du validation set\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')) #Save les meilleurs NN\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(np.asarray(train_x),  np.asarray(train_y), \n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(np.asarray(valid_x), np.asarray(valid_y)),\n",
    "                    callbacks=[tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Evaluation du model et sauveguarde apres entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(np.asarray(valid_x), np.asarray(valid_y), verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "filepath = \"models/{}\".format(NAME)\n",
    "model.save(filepath, save_format=\"h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
